{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00809805-9a73-49a5-ada9-da346d4bcb46",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "import math\n",
    "import umap\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import umap\n",
    "from tqdm import tqdm\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from matplotlib.image import imread\n",
    "\n",
    "from PIL import Image,ImageOps\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "from matplotlib.colors import Normalize\n",
    "from matplotlib.cm import ScalarMappable\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65cbd68d-bce5-48cb-84d7-405f19122434",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "plt.rcParams.update({\n",
    "    \"font.family\" : 'Arial',   # specify font family here\n",
    "    \"font.size\" : 12,\n",
    "    \"font.weight\" : \"normal\"})          # specify font size here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db01b8f-8586-46ea-81d3-7219f0bffd31",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8386a503-e721-413f-a357-60f860735b0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/jinny/projects/Art-history/Art-history/datas/'\n",
    "file_info = pd.read_csv(base_path+'file_info.csv')\n",
    "\n",
    "# file_info_latent\n",
    "df = pd.DataFrame(( np.load(base_path+'vectors/avec_latents.npy', allow_pickle=True)),columns=['avec','Path'])\n",
    "file_info_latents = pd.merge(file_info, df, how = 'left', on = 'Path')\n",
    "file_info_latents = file_info_latents[~file_info_latents.avec.isnull()]\n",
    "\n",
    "avec = np.array([i.reshape(-1) for i in file_info_latents['avec']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c35a5a-c793-4735-8ce9-f4a3205e8389",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(np.load(base_path+'vectors/cvec_latents.npy', allow_pickle=True),columns=['cvec','Path'])\n",
    "file_info_latents = pd.merge(file_info_latents, df, how = 'left', on = 'Path')\n",
    "\n",
    "cvec = np.array([i.reshape(-1) for i in file_info_latents['cvec']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "127b5abf-748d-4224-b712-72671ec7ce7e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_avec = PCA(n_components=5,random_state=42)\n",
    "pca_fit = pca_avec.fit_transform(avec)\n",
    "pca_avec_df = pd.DataFrame(data=pca_fit)\n",
    "\n",
    "pca_avec_df.columns = ['avec_pc'+str(i+1) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8164d29-9ff1-4295-8ceb-650e8a50f19f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pca_cvec = PCA(n_components=5,random_state=42)\n",
    "pca_fit = pca_cvec.fit_transform(cvec)\n",
    "pca_cvec_df = pd.DataFrame(data=pca_fit)\n",
    "\n",
    "pca_cvec_df.columns = ['cvec_pc'+str(i+1) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dc59bc-40b3-41b4-b663-ce5bd6ebea2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_info_latents = pd.concat([file_info_latents,pca_avec_df.iloc[:,:5]],axis=1)\n",
    "file_info_latents = pd.concat([file_info_latents,pca_cvec_df.iloc[:,:5]],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcf697d0-9c9e-450f-97c2-20cc5f6965b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_file_info_latents = file_info_latents[file_info_latents['new_date']>=1500].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0942526-c718-41e2-99d4-b2a55333e16d",
   "metadata": {},
   "source": [
    "### graph-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6541da3e-b06f-4fcb-b70b-93a2ba44e814",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_pca_ridge(pc, vec, ticks):\n",
    "    sns.set(style=\"white\", rc={\"axes.facecolor\": (0, 0, 0, 0)})\n",
    "\n",
    "    # new_date 값을 내림차순으로 정렬\n",
    "    temp_file_info_latents_sorted = temp_file_info_latents.sort_values(by=\"new_date\", ascending=False)\n",
    "    unique_dates = sorted(temp_file_info_latents[\"new_date\"].unique())\n",
    "\n",
    "    # FacetGrid를 사용하여 데이터 분리 (내림차순 정렬된 데이터 사용)\n",
    "    g = sns.FacetGrid(\n",
    "        temp_file_info_latents,\n",
    "        row=\"new_date\",\n",
    "        hue=\"new_date\",\n",
    "        aspect=30,\n",
    "        height=0.2,\n",
    "        palette=\"Spectral_r\",\n",
    "        row_order=unique_dates,\n",
    "    )\n",
    "    years = list(temp_file_info_latents[\"new_date\"].unique())\n",
    "\n",
    "    # 각 능선에 KDE 플롯 추가\n",
    "    g.map(sns.kdeplot, f\"{vec}vec_pc{pc}\", clip_on=False, shade=True, alpha=1, lw=1, bw_adjust=0.5)\n",
    "    g.map(sns.kdeplot, f\"{vec}vec_pc{pc}\", clip_on=False, color=\"w\", lw=1.5, bw_adjust=0.5)\n",
    "\n",
    "    # 각 능선의 오버랩을 조정\n",
    "    g.map(plt.axhline, y=0, lw=2, clip_on=False)\n",
    "\n",
    "    # 그래프의 각 요소를 디자인\n",
    "    g.fig.subplots_adjust(hspace=-0.6)\n",
    "\n",
    "    # 범례 제거 및 기본 설정\n",
    "    g.set_titles(\"\")\n",
    "    g.set(yticks=[], ylabel=None, xlabel=None)\n",
    "    g.despine(bottom=True, left=True)\n",
    "\n",
    "    # # x축 수치 표시 - 마지막 subplot에만 적용\n",
    "    # for ax in g.axes[:-1].flat:\n",
    "    #     ax.set_xticks([])\n",
    "    \n",
    "    bottom_ax = g.axes[-1, 0]\n",
    "    bottom_ax.set_xticks(ticks,fontsize=25)  # x축 눈금을 설정\n",
    "    bottom_ax.set_xticklabels(ticks, fontsize=25)\n",
    "\n",
    "\n",
    "    # Colorbar 추가\n",
    "    norm = Normalize(\n",
    "        vmin=min([years.index(x) for x in temp_file_info_latents[\"new_date\"]]),\n",
    "        vmax=max([years.index(x) for x in temp_file_info_latents[\"new_date\"]]),\n",
    "    )\n",
    "    cbar_ax = g.fig.add_axes([0.95, 0.1, 0.03, 0.75])\n",
    "    sm = ScalarMappable(cmap=\"Spectral_r\", norm=norm)\n",
    "    sm.set_array([])\n",
    "    cbar = plt.colorbar(\n",
    "        sm, ax=g.axes.ravel().tolist(), cax=cbar_ax, orientation=\"vertical\", aspect=30, fraction=0.05\n",
    "    )\n",
    "    cbar.set_ticks([0, 25, 49])\n",
    "    cbar.set_ticklabels([1500, 1750, 1990], fontsize=36)\n",
    "    cbar.ax.invert_yaxis()\n",
    "\n",
    "    # 제목 추가\n",
    "    g.fig.suptitle(f\"PC{pc}\", fontsize=46, y=0.95, x=0.6)  # y로 타이틀 위치 조정\n",
    "    plt.savefig(\n",
    "        f\"/home/jinny/projects/Art-history/Art-history/graph/figure02_AB_{vec}vec_pc{pc}.svg\",\n",
    "        bbox_inches=\"tight\",\n",
    "        transparent=True,\n",
    "        dpi=600,\n",
    "    )\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "752b836c-9a7e-4823-a42c-be8777d1b3c0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "make_pca_ridge(1,'a',range(-160,161,80))\n",
    "make_pca_ridge(2,'a',range(-110,111,55))\n",
    "make_pca_ridge(1,'c',np.arange(-0.5,0.51,0.25))\n",
    "make_pca_ridge(2,'c',np.arange(-0.5,0.51,0.25))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa32fc2a-b63a-478a-aa50-82e16e961075",
   "metadata": {},
   "source": [
    "### graph-b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e307f9-a671-4aa7-bb47-91721a761625",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"./scripts\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb1d6f2-bdc9-4da9-b461-3a71546ce721",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse, os\n",
    "import PIL\n",
    "import torch\n",
    "import numpy as np\n",
    "from omegaconf import OmegaConf\n",
    "from PIL import Image\n",
    "from tqdm import tqdm, trange\n",
    "from itertools import islice\n",
    "from einops import rearrange, repeat\n",
    "from torchvision.utils import make_grid\n",
    "from torch import autocast\n",
    "from contextlib import nullcontext\n",
    "from pytorch_lightning import seed_everything\n",
    "from imwatermark import WatermarkEncoder\n",
    "import pandas as pd\n",
    "from scripts.txt2img import put_watermark\n",
    "from ldm.util import instantiate_from_config\n",
    "from ldm.models.diffusion.ddim import DDIMSampler\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img\n",
    "from matplotlib.image import imread"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2314abb2-b2c3-490d-bfeb-05a3aed820f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_path = '/home/jinny/projects/Art-history/Art-history/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c40d981-3911-44d2-902a-aa87f0680767",
   "metadata": {},
   "outputs": [],
   "source": [
    "munch = file_info_latents[file_info_latents['author_name']=='edvard munch']\n",
    "munch = munch[munch['painting_name']=='The Scream 1895']\n",
    "\n",
    "m_path = munch['Path'].values[0]\n",
    "m_latent = munch['avec'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f86b1d9-eee0-44b8-8c06-3ff3668248d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "pearl = file_info_latents[file_info_latents['author_name'].str.contains('vermeer')]\n",
    "pearl = pearl[pearl['painting_name']=='The Girl With A Pearl Earring']\n",
    "\n",
    "p_path = pearl['Path'].values[0]\n",
    "p_latent = pearl['avec'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b4fb6f6-9dec-4df7-9cd9-b5ea17941389",
   "metadata": {},
   "outputs": [],
   "source": [
    "avec_eigen_variance = pca_avec.explained_variance_ratio_\n",
    "avec_eigen_vector = pca_avec.components_\n",
    "avec_eigen_value  = pca_avec.singular_values_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210ca0a1-7779-4778-a384-16da0f76eb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chunk(it, size):\n",
    "    it = iter(it)\n",
    "    return iter(lambda: tuple(islice(it, size)), ())\n",
    "\n",
    "def load_model_from_config(config, ckpt, verbose=False):\n",
    "    print(f\"Loading model from {ckpt}\")\n",
    "    pl_sd = torch.load(ckpt, map_location=\"cpu\")\n",
    "    if \"global_step\" in pl_sd:\n",
    "        print(f\"Global Step: {pl_sd['global_step']}\")\n",
    "    sd = pl_sd[\"state_dict\"]\n",
    "    model = instantiate_from_config(config.model)\n",
    "    m, u = model.load_state_dict(sd, strict=False)\n",
    "    if len(m) > 0 and verbose:\n",
    "        print(\"missing keys:\")\n",
    "        print(m)\n",
    "    if len(u) > 0 and verbose:\n",
    "        print(\"unexpected keys:\")\n",
    "        print(u)\n",
    "\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "    return model\n",
    "\n",
    "def load_model(cudanum) :\n",
    "\n",
    "    config = OmegaConf.load(base_path+f\"scripts/configs/stable-diffusion/v2-inference.yaml\")\n",
    "    model = load_model_from_config(config, base_path+f\"scripts/configs/checkpoint/512-base-ema.ckpt\") \n",
    "\n",
    "    GPU_NUM=cudanum\n",
    "    \n",
    "    # GPU 할당 변경하기\n",
    "    device = torch.device(f'cuda:{GPU_NUM}' if torch.cuda.is_available() else 'cpu')\n",
    "    torch.cuda.set_device(device) # change allocation of current GPU\n",
    "    print ('Current cuda device ', torch.cuda.current_device()) # check\n",
    "\n",
    "    model = model.to(device)\n",
    "    return model,device\n",
    "\n",
    "def load_img(path):\n",
    "    image = Image.open(path).convert(\"RGB\")\n",
    "    w, h = image.size\n",
    "    print(f\"loaded input image of size ({w}, {h}) from {path}\")\n",
    "    w, h = map(lambda x: x - x % 64, (w, h))  # resize to integer multiple of 64\n",
    "    image = image.resize((w, h), resample=PIL.Image.LANCZOS)\n",
    "    image = np.array(image).astype(np.float32) / 255.0\n",
    "    image = image[None].transpose(0, 3, 1, 2)\n",
    "    image = torch.from_numpy(image)\n",
    "    return 2. * image - 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a604c988-faf6-4653-9181-53953b816d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_diffusion_model_changing_denoising_steps(init_latent,prompt,n,num,batch,model,device):  \n",
    "    \n",
    "    ddim_steps = 50\n",
    "    ddim_eta = 0.0\n",
    "    n_iter = 1\n",
    "    batch_size = batch\n",
    "    scale = 9.0\n",
    "    \n",
    "    sampler = DDIMSampler(model)\n",
    "    sampler.make_schedule(ddim_num_steps=ddim_steps, ddim_eta=ddim_eta, verbose=False)\n",
    "    precision_scope = autocast\n",
    "    \n",
    "    all_samples = []\n",
    "    all_samples_enc = []\n",
    "    for i in range(n):\n",
    "        #strength = 0.8\n",
    "        strength = 1/ddim_steps * (i+num) # change strength to control denoising steps\n",
    "        data = [batch_size * [prompt]]\n",
    "        t_enc = int(strength * ddim_steps)\n",
    "        sampler.make_schedule(ddim_num_steps=ddim_steps, ddim_eta=ddim_eta, verbose=False)\n",
    "        with torch.no_grad():\n",
    "            with precision_scope(\"cuda\"):\n",
    "                with model.ema_scope():\n",
    "                    for n in trange(n_iter, desc=\"Sampling\"):\n",
    "                        for prompts in tqdm(data, desc=\"data\"):\n",
    "                            uc = None\n",
    "                            if scale != 1.0:\n",
    "                                uc = model.get_learned_conditioning(batch_size * [\"\"])\n",
    "                            if isinstance(prompts, tuple):\n",
    "                                prompts = list(prompts)\n",
    "                            c = model.get_learned_conditioning(prompts)\n",
    "                            if prompt == \"no prompt\" :\n",
    "                                print(\"change prompt vector to zero\")\n",
    "                                c = torch.zeros(c.shape[0], c.shape[1], c.shape[2]).to('cuda:0') # change prompt vector to zero (i.e., no direction)\n",
    "\n",
    "                            # encode (scaled latent)\n",
    "                            z_enc = sampler.stochastic_encode(init_latent, torch.tensor([t_enc] * batch_size).to(device))\n",
    "                            # decode it\n",
    "                            samples = sampler.decode(z_enc, c, t_enc, unconditional_guidance_scale=scale,\n",
    "                                                     unconditional_conditioning=uc, )\n",
    "\n",
    "                            x_samples = model.decode_first_stage(samples)\n",
    "                            x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "                            \n",
    "        #draw_image(x_samples[0])\n",
    "        all_samples.append(x_samples)\n",
    "        all_samples_enc.append(samples)\n",
    "               \n",
    "    return all_samples_enc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b2149f6-77e1-47f2-8a5e-dc695baf1d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_2latent(path,model) :\n",
    "    file_info = pd.read_csv(base_path+'datas/file_info.csv')\n",
    "\n",
    "    image_latent = []\n",
    "    for i in path :\n",
    "        init_image = load_img(base_path+'datas/resized_image/'+i).to(device)\n",
    "        init_latent = model.get_first_stage_encoding(model.encode_first_stage(init_image))\n",
    "        init_latent = init_latent.view([-1])\n",
    "        image_latent.append(init_latent.cpu().numpy())\n",
    "\n",
    "    #latent_df = pd.DataFrame(image_latent)\n",
    "    return image_latent\n",
    "\n",
    "def model_2img(latent_samples, model) :\n",
    "    precision_scope = autocast \n",
    "    with torch.no_grad():\n",
    "        with precision_scope(\"cuda\"):\n",
    "            with model.ema_scope():\n",
    "                \n",
    "                x_samples = model.decode_first_stage(latent_samples)\n",
    "                x_samples = torch.clamp((x_samples + 1.0) / 2.0, min=0.0, max=1.0)\n",
    "\n",
    "                for x_sample in x_samples:\n",
    "                    x_sample = 255. * rearrange(x_sample.cpu().numpy(), 'c h w -> h w c')\n",
    "                    img = Image.fromarray(x_sample.astype(np.uint8))\n",
    "                    #img = put_watermark(img, wm_encoder)\n",
    "                    return img\n",
    "                    # plt.imshow(img)\n",
    "                    # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4eddce-965a-48a2-9ff0-f8d6846995fb",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "# model load\n",
    "model,device = load_model(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b40965-7f3c-45c1-9302-1027aa646da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_vector_along_pca_axis(vector, pca_axis, distance):\n",
    "    # 벡터를 복사하여 원본 벡터를 변경하지 않도록 함\n",
    "    moved_vector = np.copy(vector)\n",
    "    normalized_pca_axis = np.copy(pca_axis)\n",
    "    \n",
    "\n",
    "    normalized_pca_axis = normalized_pca_axis / np.linalg.norm(normalized_pca_axis)\n",
    "    # PCA 축 벡터에 특정 거리만큼 스케일링하여 이동\n",
    "    moved_vector += distance * normalized_pca_axis\n",
    "\n",
    "    return moved_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81985897-38ca-415b-a2f1-c185d70f6219",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_img(pc_num) :\n",
    "    change_latnets1 = list()\n",
    "    # original\n",
    "    change_latnet = move_vector_along_pca_axis(m_latent,avec_eigen_vector[pc_num],0)\n",
    "    change_latnet = torch.Tensor(change_latnet.reshape(1,4,64,64)).cuda()\n",
    "    change_latnets1.append(change_latnet)\n",
    "    # min\n",
    "    change_latnet = move_vector_along_pca_axis(m_latent,avec_eigen_vector[pc_num],-pca_avec_df[f'avec_pc{pc_num+1}'][munch.index.values[0]]+min(pca_avec_df[f'avec_pc{pc_num+1}']))\n",
    "    change_latnet = torch.Tensor(change_latnet.reshape(1,4,64,64)).cuda()\n",
    "    change_latnets1.append(change_latnet)\n",
    "    # max\n",
    "    change_latnet = move_vector_along_pca_axis(m_latent,avec_eigen_vector[pc_num],-pca_avec_df[f'avec_pc{pc_num+1}'][munch.index.values[0]]+max(pca_avec_df[f'avec_pc{pc_num+1}']))\n",
    "    change_latnet = torch.Tensor(change_latnet.reshape(1,4,64,64)).cuda()\n",
    "    change_latnets1.append(change_latnet)\n",
    "\n",
    "    # move \n",
    "    change_latnets2 = list()\n",
    "    for i in range(13) :\n",
    "        change_latnet = move_vector_along_pca_axis(m_latent,avec_eigen_vector[pc_num],-pca_avec_df[f'avec_pc{pc_num+1}'][munch.index.values[0]]-300+i*50)\n",
    "        change_latnet = torch.Tensor(change_latnet.reshape(1,4,64,64)).cuda()\n",
    "        change_latnets2.append(change_latnet)\n",
    "    return change_latnets1,change_latnets2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbaaaf15-20f3-47ae-82c7-5358bcdc51b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image_on_graph(x_coord,y_coord, change_latnet, ax,color,border):\n",
    "   # 이미지 불러오기\n",
    "    img = model_2img(change_latnet, model)\n",
    "\n",
    "    # 이미지 크기 조정\n",
    "    img = img.resize((80, 80))\n",
    "    img = ImageOps.expand(img, border=border, fill=color)\n",
    "\n",
    "    # 그래프 좌표계에 맞춰 이미지를 배치 (imshow 사용)\n",
    "    imagebox = OffsetImage(img, zoom=1)\n",
    "    ab = AnnotationBbox(imagebox, (x_coord, y_coord), frameon=False, zorder=10)\n",
    "    \n",
    "    # 이미지 배치\n",
    "    ax.add_artist(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00a9febc-489d-4e4d-888c-3129c4111569",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_img_info = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c18d592-80e8-47b0-bd86-28b09e38b9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for pc_num in range(4) :\n",
    "    # 그래프 그리기\n",
    "    ### 라인 그리기\n",
    "    y_point = 0.76\n",
    "    fig, ax = plt.subplots(figsize=(14,5))\n",
    "    x_values = [-230,230]\n",
    "    y_values = [y_point,y_point]\n",
    "    ax.plot(x_values, y_values,color='black',zorder=1,linewidth=1)\n",
    "    ### 점 그리기\n",
    "    x_values = [-200+50*i for i in range(9)]\n",
    "    y_values = [y_point for i in range(len(x_values))]\n",
    "    ax.scatter(x_values, y_values,c='black',s=35,zorder=3)\n",
    "    ax.plot([-230, -230], [y_point-0.05, y_point+0.05], color='black', linewidth=1)  # 왼쪽 막대기\n",
    "    ax.plot([230, 230], [y_point-0.05, y_point+0.05], color='black', linewidth=1)    # 오른쪽 막대기\n",
    "    ### min,max,original 점 그리기\n",
    "    x_values = [min(pca_avec_df[f'avec_pc{pc_num+1}']), pca_avec_df[f'avec_pc{pc_num+1}'][munch.index.values[0]], pca_avec_df[f'avec_pc{pc_num+1}'][pearl.index.values[0]], max(pca_avec_df[f'avec_pc{pc_num+1}'])]\n",
    "    y_values = [y_point for i in range(len(x_values))]\n",
    "    ax.scatter(x_values, y_values, c='red',s=100,zorder=5)\n",
    "    # munch\n",
    "    ax.scatter(x_values[1], y_values[1], c='green',s=100,zorder=5)\n",
    "    # pearl\n",
    "    ax.scatter(x_values[2], y_values[2], c='blue',s=100,zorder=5)\n",
    "\n",
    "    ### img path\n",
    "    temp_df = pca_avec_df.copy()\n",
    "    temp_df['pc-min'] = temp_df[f'avec_pc{pc_num+1}'] - min(pca_avec_df[f'avec_pc{pc_num+1}'])\n",
    "    temp_df['pc-max'] = temp_df[f'avec_pc{pc_num+1}'] - max(pca_avec_df[f'avec_pc{pc_num+1}'])\n",
    "\n",
    "    temp_df = temp_df.reset_index()\n",
    "\n",
    "    temp_df_min = temp_df.sort_values('pc-min')\n",
    "    min_path = file_info_latents['avec'][file_info_latents.index == temp_df_min['index'].iloc[0]].values[0]\n",
    "\n",
    "    temp_df_max = temp_df.sort_values('pc-max')\n",
    "    max_path = file_info_latents['avec'][file_info_latents.index == temp_df_max['index'].iloc[-1]].values[0]\n",
    "\n",
    "    plt.xlim([-235, 235])      \n",
    "    plt.ylim([-0.2, 2])\n",
    "    plt.gca().axes.yaxis.set_visible(False) \n",
    "    plt.xticks(fontsize=30)\n",
    "\n",
    "    ## sample 좌표\n",
    "    sam = (pca_avec_df[f'avec_pc{pc_num+1}'][munch.index.values[0]] + pca_avec_df[f'avec_pc{pc_num+1}'][pearl.index.values[0]])/2\n",
    "    text_positions = [sam-27,sam+27,min(pca_avec_df[f'avec_pc{pc_num+1}']),max(pca_avec_df[f'avec_pc{pc_num+1}'])] # 텍스트를 추가할 위치들의 x, y 좌표 리스트\n",
    "\n",
    "    # img\n",
    "    if pca_avec_df[f'avec_pc{pc_num+1}'][pearl.index.values[0]] - pca_avec_df[f'avec_pc{pc_num+1}'][munch.index.values[0]] < 60 :\n",
    "        xm_coords_image = sam-27\n",
    "        xp_coords_image = sam+27\n",
    "    else :\n",
    "        xm_coords_image = pca_avec_df[f'avec_pc{pc_num+1}'][munch.index.values[0]]\n",
    "        xp_coords_image = pca_avec_df[f'avec_pc{pc_num+1}'][pearl.index.values[0]]\n",
    "        text_positions[0] = xm_coords_image\n",
    "        text_positions[1] = xp_coords_image    \n",
    "        \n",
    "    y_coords_image = 1.5\n",
    "\n",
    "    x1_coords_images = [i for i in [min(pca_avec_df[f'avec_pc{pc_num+1}']),max(pca_avec_df[f'avec_pc{pc_num+1}'])] ]\n",
    "    y1_coords_images = [y_coords_image for i in range(len(x1_coords_images))]\n",
    "\n",
    "    x2_coords_images = [(i*50)-200 for i in range(9)]\n",
    "    y2_coords_images = [0.3 for i in range(len(x2_coords_images))]\n",
    "\n",
    "    # 텍스트 쓰기\n",
    "    text_y = 0.98\n",
    "    texts = ['(a)','(b)', 'min','max']  # 추가할 텍스트 내용 리스트\n",
    "    ax.text(text_positions[0], text_y, texts[0], fontsize=38, ha='center', va='center', color='green')\n",
    "    ax.text(text_positions[1], text_y, texts[1], fontsize=38, ha='center', va='center', color='blue')\n",
    "    ax.text(text_positions[2], text_y, texts[2], fontsize=38, ha='center', va='center', color='red')\n",
    "    ax.text(text_positions[3], text_y, texts[3], fontsize=38, ha='center', va='center', color='red')\n",
    "\n",
    "    result_minmax = [torch.tensor(min_path.reshape(1,4,64,64)).cuda(),torch.tensor(max_path.reshape(1,4,64,64)).cuda()]\n",
    "    result_munch = torch.tensor(m_latent.reshape(1,4,64,64)).cuda()\n",
    "    result_pearl = torch.tensor(p_latent.reshape(1,4,64,64)).cuda()\n",
    "\n",
    "    # 이미지 표시 함수 호출\n",
    "    change_latnets1,change_latnets2 = make_img(pc_num)\n",
    "    plot_image_on_graph(xm_coords_image, y_coords_image, result_munch, ax,'green',3)\n",
    "    plot_image_on_graph(xp_coords_image, y_coords_image, result_pearl, ax,'blue',3)\n",
    "    for x, y, path in zip(x1_coords_images, y1_coords_images, result_minmax):\n",
    "        plot_image_on_graph(x, y, path, ax,'red',3)\n",
    "    for x, y, path in zip(x2_coords_images, y2_coords_images, change_latnets2):\n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        plot_image_on_graph(x, y, path, ax,'black',1)\n",
    "\n",
    "    # 그림 정보 저장\n",
    "    # min, munch, pearl, max\n",
    "    # (min) point, title, author, year, (max) point, title, author, year , munch, pearl\n",
    "    temp_max = file_info_latents[file_info_latents.index == temp_df_max['index'].iloc[-1]]\n",
    "    temp_min = file_info_latents[file_info_latents.index == temp_df_min['index'].iloc[0]]\n",
    "    pc_img_info[f'A_PC{pc_num+1}'] = [min(pca_avec_df[f'avec_pc{pc_num+1}']), temp_min['painting_name'].values[0], temp_min['author_name'].values[0], temp_min['new_date'].values[0], max(pca_avec_df[f'avec_pc{pc_num+1}']), temp_max['painting_name'].values[0], temp_max['author_name'].values[0], temp_max['new_date'].values[0],\n",
    "                                    pca_avec_df[f'avec_pc{pc_num+1}'][munch.index.values[0]], pca_avec_df[f'avec_pc{pc_num+1}'][pearl.index.values[0]]]\n",
    "\n",
    "    # 그래프 보여주기\n",
    "    plt.title(f'PC{pc_num+1}',fontsize=45, pad=10)\n",
    "    plt.savefig(f'/home/jinny/projects/Art-history/Art-history/graph/figure02_C_pc{pc_num+1}.svg',bbox_inches='tight',transparent = True,dpi=600)\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54186e4-73aa-460d-8670-b845f8678e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_vector_PC_image_info = pd.DataFrame(pc_img_info).T\n",
    "A_vector_PC_image_info.columns = ['min_point', 'min_title', 'min_author', 'min_date', 'max_point', 'max_title', 'max_author', 'max_date', 'munch', 'pearl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc0139f-046f-4d1f-b6a4-febe52f06c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "A_vector_PC_image_info"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9efa7c-dbdc-454c-bab0-116f35a6961f",
   "metadata": {},
   "source": [
    "### graph-C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "990a6294-c3c4-46c7-81db-cfb99dce8d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cvec_eigen_variance = pca_cvec.explained_variance_ratio_\n",
    "cvec_eigen_vector = pca_cvec.components_\n",
    "cvec_eigen_value  = pca_cvec.singular_values_ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8390ea65-ba30-44e8-a47e-5847ee9257b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cos(a,b):\n",
    "    return np.dot(a,b) / (np.linalg.norm(a) * np.linalg.norm(b))\n",
    "\n",
    "def sin(a,b):\n",
    "    return np.sqrt(1-cos(a,b)**2)\n",
    "\n",
    "for i in range(5) :\n",
    "    cvec_pc_dist = list()\n",
    "    for latent in cvec :\n",
    "        cvec_pc_dist.append(np.linalg.norm(latent) * sin(latent,cvec_eigen_vector[i]))\n",
    "    file_info_latents[f'cvec_pc{i+1}_dist'] = cvec_pc_dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36b35e4-0233-4f75-b0a9-d03c2b4142b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def c_plot_image_on_graph(x_coord,y_coord, change_latnet, ax,color,border):\n",
    "   # 이미지 불러오기\n",
    "    img = model_2img(change_latnet, model)\n",
    "\n",
    "    # 이미지 크기 조정\n",
    "    img = img.resize((80, 80))\n",
    "    img = ImageOps.expand(img, border=border, fill=color)\n",
    "\n",
    "    # 그래프 좌표계에 맞춰 이미지를 배치 (imshow 사용)\n",
    "    imagebox = OffsetImage(img, zoom=1)\n",
    "    ab = AnnotationBbox(imagebox, (x_coord, y_coord), frameon=False, zorder=10)\n",
    "    \n",
    "    # 이미지 배치\n",
    "    ax.add_artist(ab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607e889b-7587-45f5-b622-56dea38ad12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pc_img_info = dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a3e4a73-eadb-4e84-af49-8a5c530585cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "for pc_num in range(4) :\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(14, 5))\n",
    "    \n",
    "    special_x = [file_info_latents[f'cvec_pc{pc_num+1}'].min(),file_info_latents[f'cvec_pc{pc_num+1}'].max()] \n",
    "    x = np.linspace(special_x[0]+0.015, special_x[1]-0.015, 9)  # 중간 9개의 점\n",
    "    y_point = 0.75\n",
    "    \n",
    "\n",
    "    # 선\n",
    "    ax.plot([special_x[0]-0.06, special_x[1]+0.06], [y_point,y_point], color='black', linewidth=1)\n",
    "    # 양 끝에 세로 막대기 추가\n",
    "    ax.plot([special_x[0]-0.06, special_x[0]-0.06], [y_point-0.05,y_point+0.05], color='black', linewidth=1)  # 왼쪽 막대기\n",
    "    ax.plot([special_x[1]+0.06, special_x[1]+0.06], [y_point-0.05,y_point+0.05], color='black', linewidth=1)    # 오른쪽 막대기\n",
    "    \n",
    "    # 점\n",
    "    ax.scatter(x, np.zeros_like(x)+y_point, color='black', zorder=5)\n",
    "    # special 점\n",
    "    ax.scatter(special_x, np.zeros_like(special_x)+y_point, color='red', zorder=5,s=100)\n",
    "    # m&p\n",
    "    ax.scatter(pca_cvec_df[f'cvec_pc{pc_num+1}'][munch.index.values[0]], y_point, color='green', zorder=5,s = 100)\n",
    "    ax.scatter(pca_cvec_df[f'cvec_pc{pc_num+1}'][pearl.index.values[0]], y_point, color='blue', zorder=5,s = 100)\n",
    "    \n",
    "    \n",
    "    # 범위와 눈금 설정\n",
    "    plt.xlim(special_x[0]-0.07, special_x[1]+0.07)\n",
    "    plt.ylim(-0.2, 2)  # y축 범위 설정 (이미지를 넣을 충분한 공간 확보)\n",
    "    plt.gca().axes.yaxis.set_visible(False) \n",
    "    plt.xticks([ round(i,2) for i in np.linspace(special_x[0]+0.015, special_x[1]-0.015, 5)],fontsize=30)\n",
    "\n",
    "    # img path\n",
    "    temp_df = pca_cvec_df.copy()\n",
    "    temp_df['pc-min'] = temp_df[f'cvec_pc{pc_num+1}'] - min(pca_cvec_df[f'cvec_pc{pc_num+1}'])\n",
    "    temp_df['pc-max'] = temp_df[f'cvec_pc{pc_num+1}'] - max(pca_cvec_df[f'cvec_pc{pc_num+1}'])\n",
    "\n",
    "    temp_df = temp_df.reset_index()\n",
    "\n",
    "    temp_df_min = temp_df.sort_values('pc-min')\n",
    "    min_latent = file_info_latents['avec'][file_info_latents.index == temp_df_min['index'].iloc[0]].values[0]\n",
    "\n",
    "    temp_df_max = temp_df.sort_values('pc-max')\n",
    "    max_latent = file_info_latents['avec'][file_info_latents.index == temp_df_max['index'].iloc[-1]].values[0]\n",
    "\n",
    "\n",
    "    #### img\n",
    "    # min\n",
    "    ax.text(special_x[0], y_point+0.1, 'min', color='red', fontsize=38, ha='center')\n",
    "    c_plot_image_on_graph(special_x[0],y_point+0.7, torch.tensor(min_latent.reshape(1,4,64,64)).cuda(), ax,'red',3)\n",
    "    \n",
    "    # a - munch\n",
    "    ax.text(pca_cvec_df[f'cvec_pc{pc_num+1}'][munch.index.values[0]], y_point+0.1, '(a)', color='green', fontsize=38, ha='center')\n",
    "    c_plot_image_on_graph(pca_cvec_df[f'cvec_pc{pc_num+1}'][munch.index.values[0]],y_point+0.7, torch.tensor(m_latent.reshape(1,4,64,64)).cuda(), ax,'green',3)\n",
    " \n",
    "    # b - pearl\n",
    "    ax.text(pca_cvec_df[f'cvec_pc{pc_num+1}'][pearl.index.values[0]], y_point+0.1, '(b)', color='blue', fontsize=38, ha='center')\n",
    "    c_plot_image_on_graph(pca_cvec_df[f'cvec_pc{pc_num+1}'][pearl.index.values[0]],y_point+0.7, torch.tensor(p_latent.reshape(1,4,64,64)).cuda(), ax,'blue',3)\n",
    " \n",
    "    # max\n",
    "    ax.text(special_x[1], y_point+0.1, 'max', color='red', fontsize=38, ha='center')\n",
    "    c_plot_image_on_graph(special_x[1],y_point+0.7, torch.tensor(max_latent.reshape(1,4,64,64)).cuda(), ax,'red',3)\n",
    "\n",
    "    # pca img\n",
    "    for i, xpos in enumerate(x):\n",
    "        min_value = file_info_latents[f'cvec_pc{pc_num+1}_dist'][(file_info_latents[f'cvec_pc{pc_num+1}']>xpos-0.015) &  (file_info_latents[f'cvec_pc{pc_num+1}']< xpos+0.015)].min()\n",
    "        point = file_info_latents['avec'][file_info_latents[f'cvec_pc{pc_num+1}_dist']== min_value].values[0] \n",
    "        plt.subplots_adjust(top=0.9)\n",
    "        c_plot_image_on_graph(xpos,y_point-0.5, torch.Tensor(point.reshape(1,4,64,64)).cuda(), ax,'black',1)\n",
    "\n",
    "    # 그림 정보 저장\n",
    "    # min, munch, pearl, max\n",
    "    # (min) point, title, author, year, (max) point, title, author, year , munch, pearl\n",
    "    temp_max = file_info_latents[file_info_latents.index == temp_df_max['index'].iloc[-1]]\n",
    "    temp_min = file_info_latents[file_info_latents.index == temp_df_min['index'].iloc[0]]\n",
    "    pc_img_info[f'C_PC{pc_num+1}'] = [min(pca_cvec_df[f'cvec_pc{pc_num+1}']), temp_min['painting_name'].values[0], temp_min['author_name'].values[0], temp_min['new_date'].values[0], max(pca_cvec_df[f'cvec_pc{pc_num+1}']), temp_max['painting_name'].values[0], temp_max['author_name'].values[0], temp_max['new_date'].values[0],\n",
    "                                    pca_cvec_df[f'cvec_pc{pc_num+1}'][munch.index.values[0]], pca_cvec_df[f'cvec_pc{pc_num+1}'][pearl.index.values[0]]]\n",
    "\n",
    "\n",
    "    plt.title(f'PC{pc_num+1}',fontsize=45, pad=10)\n",
    "    plt.savefig(f'/home/jinny/projects/Art-history/Art-history/graph/figure02_D_pc{pc_num+1}.svg',bbox_inches='tight',transparent = True,dpi=600)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae138c59-9dda-4c60-9686-a1a475403e81",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vector_PC_image_info = pd.DataFrame(pc_img_info).T\n",
    "C_vector_PC_image_info.columns = ['min_point', 'min_title', 'min_author', 'min_date', 'max_point', 'max_title', 'max_author', 'max_date', 'munch', 'pearl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3607289f-7919-428e-a34e-68480cc48671",
   "metadata": {},
   "outputs": [],
   "source": [
    "C_vector_PC_image_info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "351b0281-ad45-450a-9fb2-48279e840655",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.concat([A_vector_PC_image_info,C_vector_PC_image_info]).to_csv('/home/jinny/projects/Art-history/Art-history/graph/datas/pc_point_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4046c3c7-75c0-4f9a-9947-ff5151fa4d1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cda702e-e348-46e0-8605-9aa9ecc6449a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "history",
   "language": "python",
   "name": "history"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
